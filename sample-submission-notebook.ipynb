{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":838.303304,"end_time":"2023-06-09T09:12:18.127930","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-06-09T08:58:19.824626","version":"2.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":69003,"databundleVersionId":7667221,"sourceType":"competition"}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<span style=\"color:rgb(0, 174, 209); font-size:36px; font-weight: bold;\">RED 5R - Premio CERVERA - Guía básica de aplicación</span>\n\n<img src=\"https://red5r.es/wp-content/uploads/2022/03/Red-5R-Red-Cervera-300x109.png\" alt=\"RED 5R LOGO\" style=\"width: 25%; margin-left: 25%;\">\n\nEl objetivo de este Notebook es servir cómo guía para los participantes de la competición la cual se encuentra situada dentro de las actividades del proyecto “5R – Red Cervera de tecnologías robóticas en fabricación inteligente”, financiado por el Ministerio de Ciencia e Innovación a través del Centro para el Desarrollo Tecnológico Industrial (CDTI), número de contrato CER-20211007, en el marco del programa “Centros Tecnológicos de Excelencia Cervera”. La red se encuentra formada por los siguientes centros: TEKNIKER, EURECAT, AIMEN, CARTIF y CATEC.\n\nLa competición se puede encontrar en el siguiente link de la plataforma Kaggle: [RED 5R - Competition Home Page](https://www.kaggle.com/competitions/5r-competicion/overview)","metadata":{"id":"IYasnTqQ4FCZ","papermill":{"duration":0.005627,"end_time":"2023-06-09T08:58:35.105752","exception":false,"start_time":"2023-06-09T08:58:35.100125","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 1. Configuración inicial\n\nEn este primer paso se importarán las librerías y módulos que serán necesarios en este Notebook.","metadata":{"id":"NbXUeSmjgKoC","papermill":{"duration":0.006222,"end_time":"2023-06-09T08:58:35.143153","exception":false,"start_time":"2023-06-09T08:58:35.136931","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, glob\nimport numpy as np\nimport pandas as pd","metadata":{"id":"db04d9de-1357-4a3b-a80c-f8e6f938440d","outputId":"072a4636-6c23-41e4-eee8-f38d607efb6a","papermill":{"duration":33.434628,"end_time":"2023-06-09T08:59:08.595631","exception":false,"start_time":"2023-06-09T08:58:35.161003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-04T21:55:52.334487Z","iopub.execute_input":"2024-03-04T21:55:52.334976Z","iopub.status.idle":"2024-03-04T21:55:52.790303Z","shell.execute_reply.started":"2024-03-04T21:55:52.334934Z","shell.execute_reply":"2024-03-04T21:55:52.789117Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Además, se incluye un ejemplo de cómo obtener una lista con los nombres de las imágenes \"default\" tanto del TRAIN como del VALIDATION dataset. Esta metodología se puede aprovechar para obtener la lista de nombres de las máscaras binarias, etc.","metadata":{"id":"b70ItMfw_jWi","papermill":{"duration":0.008193,"end_time":"2023-06-09T08:59:08.615577","exception":false,"start_time":"2023-06-09T08:59:08.607384","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define the base directories\ntrain_base_dir = '/kaggle/input/5r-competicion/TRAIN/TRAIN/'\nvalid_base_dir = '/kaggle/input/5r-competicion/VALIDATION/VALIDATION/'\n\n# Function to get image paths containing 'defaultImage' in the name and are PNG files\ndef get_paths_with_default_image_and_png(base_dir):\n    image_paths = []\n    for root, dirs, files in os.walk(base_dir):\n        for file in files:\n            if 'defaultImage' in file and file.lower().endswith('.png'):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\n# Get train_paths and valid_paths\ntrain_paths = get_paths_with_default_image_and_png(train_base_dir)\nvalid_paths = get_paths_with_default_image_and_png(valid_base_dir)\n\nprint(train_paths[0])\nprint(valid_paths[0])","metadata":{"id":"9a7f52ed","outputId":"3849a116-1f3d-427f-820c-333020fb018b","papermill":{"duration":0.368916,"end_time":"2023-06-09T08:59:08.997307","exception":false,"start_time":"2023-06-09T08:59:08.628391","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-04T21:57:24.832007Z","iopub.execute_input":"2024-03-04T21:57:24.832730Z","iopub.status.idle":"2024-03-04T21:57:24.889729Z","shell.execute_reply.started":"2024-03-04T21:57:24.832690Z","shell.execute_reply":"2024-03-04T21:57:24.888509Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/5r-competicion/TRAIN/TRAIN/20240109_122904/20240109_122904_defaultImage.png\n/kaggle/input/5r-competicion/VALIDATION/VALIDATION/20240109_123030/20240109_123030_defaultImage.png\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Entrenamiento\n\nA continuación, el siguiente paso consiste entrenar el modelo de aprendizaje automático o aprendizaje profundo. Esta sección incluye la carga de los datos de entrenamiento, los pasos de preprocesamiento, la definición de la arquitectura del modelo y el bucle de entrenamiento. Es recomendable mostrar las métricas relevantes y así como supervisar el progreso del entrenamiento.","metadata":{}},{"cell_type":"code","source":"# Include your code here","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Inferencia\n\nUna vez entrenado el modelo, el siguiente paso consiste en obtener las predicciones del modelo sobre un conjunto de datos separado, a menudo el conjunto de prueba o nuevos datos no vistos. En esta sección se incluye la carga de los pesos del modelo entrenado, el preprocesamiento de los datos de prueba, la realización de predicciones y la evaluación del rendimiento del modelo en el conjunto de prueba.","metadata":{}},{"cell_type":"code","source":"# Include your code here","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Codificación RLE (Run Length Encoding)\n\nSe incluyen algunas funciones  útiles para codificar las máscaras obtenidas en las predicciones del modelo. Esta codificación de las imágenes es necesaria para generar posteriormente el archivo de entrega. Esta codificación se utiliza para reducir el tamaño del archivo CSV de entrega y para simplificar el proceso de evaluación.","metadata":{}},{"cell_type":"code","source":"# Custom function to encode binary mask\ndef encode_binary_mask(mask: np.ndarray) -> t.Text:\n    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n    # Check input mask\n    if mask.dtype != np.uint8:\n        raise ValueError(\n            \"encode_binary_mask expects a binary mask, received dtype == %s\" % mask.dtype\n        )\n\n    mask = np.squeeze(mask)\n    if len(mask.shape) != 2:\n        raise ValueError(\n            \"encode_binary_mask expects a 2d mask, received shape == %s\" % mask.shape\n        )\n\n    # Convert input mask to expected COCO API input\n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n\n    # RLE encode mask\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n    # Compress and base64 encoding\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str.decode(\"utf-8\")  # Return as string","metadata":{"execution":{"iopub.status.busy":"2024-03-04T17:20:26.211675Z","iopub.status.idle":"2024-03-04T17:20:26.212523Z","shell.execute_reply.started":"2024-03-04T17:20:26.212190Z","shell.execute_reply":"2024-03-04T17:20:26.212212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Generar Entrega\n\nEl último paso consiste en generar el archivo de entrega denominado `submission.csv` donde se almacenan las predicciones.\n\nEl archivo CSV de envío debe tener las siguientes columnas:\n\n- ID: Identificador único de la imagen (también denominado escena).\n- Width: anchura de la imagen\n- Height: La altura de la imagen\n- EncodedMasks: Las máscaras binarias codificadas de la imagen (separadas por espacios)\n\nEs importante asegurarse de que el archivo CSV enviado tiene el formato correcto y de que están presentes todas las columnas requeridas. Cualquier incoherencia en el formato o ausencia de columnas puede dar lugar a errores de evaluación.\n\nUtilice el siguiente código como ejemplo para generar su archivo \"submission.csv\".","metadata":{}},{"cell_type":"code","source":"# Generate submission DataFrame\nsubmission_df = pd.DataFrame(columns=['ID', 'Width', 'Height', 'EncodedPixels'])\n\nfor i, image_identifier in enumerate(image_files_paths):\n    image_id = os.path.basename(image_identifier)\n    submission_df.loc[i, 'ID'] = image_id\n    height, width = image.shape\n    submission_df.loc[i, 'Width'] = width\n    submission_df.loc[i, 'Height'] = height\n    \n    encoded_masks_str = \"\"\n    for binary_mask in image_predictions_masks:\n        # Encode the binary mask\n        encoded_mask = encode_binary_mask(binary_mask)\n\n        # Append the encoded mask to the string (encoded binary masks are space-separated)\n        if encoded_masks_str:\n            encoded_masks_str += \" \" + encoded_mask\n        else:\n            encoded_masks_str = encoded_mask\n            \n    submission_df.loc[i, 'EncodedPixels'] = encoded_masks_str\n    \n# Save submission DataFrame to CSV file\nsubmission_df.to_csv('submission.csv', index=False)\n\n# Display the DataFrame\nsubmission_df.head()","metadata":{"id":"2e4ZJjVt8Nik","outputId":"98e160dc-485f-4715-ccb5-018aa6ad2a1a","papermill":{"duration":15.410776,"end_time":"2023-06-09T09:12:13.917726","exception":false,"start_time":"2023-06-09T09:11:58.506950","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-04T17:22:23.963914Z","iopub.execute_input":"2024-03-04T17:22:23.964282Z","iopub.status.idle":"2024-03-04T17:22:23.989833Z","shell.execute_reply.started":"2024-03-04T17:22:23.964253Z","shell.execute_reply":"2024-03-04T17:22:23.988689Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   ID  Width  Height EncodedPixels\n0  12    640     640          AAAA","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Width</th>\n      <th>Height</th>\n      <th>EncodedPixels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12</td>\n      <td>640</td>\n      <td>640</td>\n      <td>AAAA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}